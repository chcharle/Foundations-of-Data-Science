{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1f8e6-9db0-4794-891f-7ed01dedb253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sts\n",
    "import seaborn as sns\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827b3f3-32dc-43bf-9448-b6b1ee8fafaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## R E L E V A N T   C O D E\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = pd.read_csv('./data/kzp-2008-2020-timeseries.csv', encoding=\"ISO-8859-1\")\n",
    "df=data\n",
    "df3=data\n",
    "df5=data\n",
    "df7=data\n",
    "missing_values_df = pd.DataFrame(columns=['year', 'count'] + list(df.columns))\n",
    "\n",
    "#create df with most possible non 0 columns per year\n",
    "# Loop through each year in the 'JAHR' column\n",
    "for year in df['JAHR'].unique():\n",
    "    year_df = df[df['JAHR'] == year]\n",
    "    count = len(year_df)\n",
    "    #count missing values\n",
    "    missing_values = year_df.isnull().sum()\n",
    "    # amount of non missing values\n",
    "    non_missing_values = count - missing_values\n",
    "    #adding count\n",
    "    missing_values_df = missing_values_df.append({'year': year, 'count': count, **non_missing_values}, ignore_index=True)\n",
    "\n",
    "years = [2014, 2015, 2016, 2017, 2018, 2019, 2020] #years to keep\n",
    "cols = []\n",
    "for var in years:\n",
    "    df_year = missing_values_df[missing_values_df['year'] == var] # only want specified years\n",
    "    cols.extend([col for col in df_year.columns if (df_year[col] == 0).any()]) # add col names where value=0 to list\n",
    "cols_to_remove = list(set(cols)) # reduce the list to only include unique values\n",
    "#print(cols_to_remove)\n",
    "for var in cols_to_remove:\n",
    "    if var in df.columns:\n",
    "        df=df.drop(var, axis=1)\n",
    "        #print(var,\",was dropped\")\n",
    "years_to_drop=[2013,2012,2011,2010,2009,2008]\n",
    "\n",
    "df=df.drop(df[df['JAHR'].isin(years_to_drop)].index)\n",
    "df2=df\n",
    "#onehot encode certain variables\n",
    "df[\"Akt\"]=df['Akt'].astype('string')\n",
    "df[\"Akt\"]=df['Akt'].str.split(', ')\n",
    "Akt_dummies = pd.get_dummies(df['Akt'].explode())\n",
    "Akt_dummies= Akt_dummies.groupby(level=0).sum()\n",
    "Akt_dummies.columns= 'Akt_' + Akt_dummies.columns\n",
    "#print(Akt_dummies)\n",
    "\n",
    "\n",
    "df[\"SL\"]=df[\"SL\"].fillna(\"none\")\n",
    "df[\"SL\"]=df['SL'].astype('string')\n",
    "df[\"SL\"]=df['SL'].str.split(', ')\n",
    "SL_dummies = pd.get_dummies(df['SL'].explode())\n",
    "SL_dummies= SL_dummies.groupby(level=0).sum()\n",
    "SL_dummies=SL_dummies.drop(\"none\", axis=1)\n",
    "SL_dummies.columns= 'SL_' + SL_dummies.columns\n",
    "#print(SL_dummies)\n",
    "\n",
    "\n",
    "df[\"SA\"]=df[\"SA\"].fillna(\"none\")\n",
    "df[\"SA\"]=df['SA'].astype('string')\n",
    "df[\"SA\"]=df['SA'].str.split(', ')\n",
    "SA_dummies = pd.get_dummies(df['SA'].explode())\n",
    "SA_dummies= SA_dummies.groupby(level=0).sum()\n",
    "SA_dummies=SA_dummies.drop(\"none\", axis=1)\n",
    "SA_dummies.columns= 'SA_' + SA_dummies.columns\n",
    "#print(SA_dummies)\n",
    "\n",
    "df[\"WB\"]=df[\"WB\"].fillna(\"none\")\n",
    "df[\"WB\"]=df['WB'].astype('string')\n",
    "df[\"WB\"]=df['WB'].str.split(', ')\n",
    "WB_dummies = pd.get_dummies(df['WB'].explode())\n",
    "WB_dummies= WB_dummies.groupby(level=0).sum()\n",
    "WB_dummies=WB_dummies.drop(\"none\", axis=1)\n",
    "WB_dummies.columns= 'WB_' + WB_dummies.columns\n",
    "\n",
    "DF = pd.concat([df2, Akt_dummies, SL_dummies, SA_dummies, WB_dummies], axis=1)\n",
    "DF=DF.drop(['SA','SL','Akt','Unnamed: 0','WB'], axis=1)\n",
    "print(DF.columns)\n",
    "DF[['Typ', 'KT', 'Ort', 'RForm']]=df[['Typ', 'KT', 'Ort', 'RForm']].astype('category')\n",
    "DF['JAHR']=DF['JAHR'].astype(CategoricalDtype(categories=[2014, 2015, 2016, 2017, 2018, 2019, 2020],ordered=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ee351-a023-46bf-ba14-ec8f321cbadc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Define a custom CSS style to make tables horizontally scrollable\n",
    "css_style = \"\"\"\n",
    "<style>\n",
    "    table.dataframe {\n",
    "        display: block;\n",
    "        overflow-x: auto;\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "HTML(css_style)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "missing_values_df = pd.DataFrame(columns=['year', 'count'] + list(DF.columns))\n",
    "\n",
    "# Loop through each year in the 'year' column\n",
    "for year in DF['JAHR'].unique():\n",
    "    # Select the rows for the current year\n",
    "    year_df = DF[DF['JAHR'] == year]\n",
    "    # Count the number of entries for the current year\n",
    "    count = len(year_df)\n",
    "    # Count the number of missing values in each column\n",
    "    missing_values = year_df.isnull().sum()\n",
    "    # Add a row to the results DataFrame\n",
    "    missing_values_df = missing_values_df.append({'year': year, 'count': count, **missing_values}, ignore_index=True)\n",
    "\n",
    "# Set the 'year' column as the index\n",
    "#missing_values_df.set_index('year', inplace=True)\n",
    "\n",
    "# Display the results\n",
    "#print(missing_values_df)\n",
    "missing_values_df\n",
    "#anzahl missing values pro zeile; optimum ist 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1dd25e-4f77-4fae-ac25-e98e3b491918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['Akt_A', 'Akt_B', 'Akt_P', 'Akt_R']\n",
    "other_columns = [col for col in DF.columns if col not in columns]\n",
    "years = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "result = pd.DataFrame(columns=['combination', 'year'] + other_columns)\n",
    "for column in columns:\n",
    "    for year in years:\n",
    "        mask = (DF[column] == 1) & (DF['JAHR'] == year)\n",
    "        missing_values = DF.loc[mask, other_columns].isnull().sum()\n",
    "        result = result.append({'combination': column, 'year': year, **missing_values}, ignore_index=True)\n",
    "\n",
    "result = result.set_index(['combination', 'year'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f40fd9-30ce-41c8-96c9-35958bd64ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = ['Akt_A', 'Akt_B', 'Akt_P', 'Akt_R']\n",
    "other_columns = [col for col in DF.columns if col not in columns]\n",
    "years = [2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "\n",
    "result = pd.DataFrame(columns=['combination', 'year', 'max_values'] + other_columns)\n",
    "for column in columns:\n",
    "    for year in years:\n",
    "        mask = (DF[column] == 1) & (DF['JAHR'] == year)\n",
    "        max_values = mask.sum()\n",
    "        missing_values = DF.loc[mask, other_columns].isnull().sum()\n",
    "        result = result.append({'combination': column, 'year': year, 'max_values': max_values, **missing_values}, ignore_index=True)\n",
    "\n",
    "result = result.set_index(['combination', 'year'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76682a38-decc-4563-8fc7-8216d15946d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(DF.groupby(['Akt_A', 'Akt_B', 'Akt_P', 'Akt_R']).size(), columns=['Count']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42f56b-764b-4ef3-9b75-270272093cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## R E L E V A N T   C O D E\n",
    "\n",
    "list_of_fixable = ['PtageStatMS', 'AustStatMS', 'BettenStat', 'DADStatMS', 'KostAmb', 'KostOKPAmb', 'KostStat', 'KostKVGStat', 'AnlKVGStat', 'KostZvOKPStat', 'AnlZvOKPStat', 'ErlOKPAmb', 'ErlKVGStat']\n",
    "list_of_bools = ['Akt_A', 'Akt_B', 'Akt_P', 'Akt_R']\n",
    "list_of_fixable_A = [element + 'A' for element in list_of_fixable]\n",
    "list_of_fixable_P = [element + 'P' for element in list_of_fixable]\n",
    "list_of_fixable_R = [element + 'R' for element in list_of_fixable]\n",
    "list_of_fixable_B = [element + 'A' for element in list_of_fixable]\n",
    "matrix_with_indices = np.zeros((len(DF), len(list_of_fixable)))\n",
    "for var in range(len(list_of_fixable)):\n",
    "    for i in range(len(DF)):\n",
    "        if DF['Akt_A'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_A[var]][i+1819]):\n",
    "            matrix_with_indices[i,var] += 1\n",
    "        elif DF['Akt_P'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_P[var]][i+1819]):\n",
    "            matrix_with_indices[i,var] += 1\n",
    "        elif DF['Akt_R'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_R[var]][i+1819]):\n",
    "            matrix_with_indices[i,var] += 1\n",
    "        elif DF['Akt_B'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_B[var]][i+1819]):\n",
    "            matrix_with_indices[i,var] += 1\n",
    "        if not ((DF['Akt_A'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_A[var]][i+1819])) or (DF['Akt_P'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_P[var]][i+1819])) or (DF['Akt_R'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_R[var]][i+1819])) or (DF['Akt_B'][i+1819] == 1 and pd.notnull(DF[list_of_fixable_B[var]][i+1819]))):\n",
    "            matrix_with_indices[i,var] -= 0\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(matrix_with_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ac213-fc45-4c6b-b96a-3d1e77fbdce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## R E L E V A N T   C O D E\n",
    "\n",
    "\n",
    "for var in range(len(list_of_fixable)):\n",
    "    for i in range(len(DF)):\n",
    "        if matrix_with_indices[i,var] == 1:\n",
    "            if pd.isnull(DF.loc[i+1819, list_of_fixable_A[var]]):\n",
    "                DF.loc[i+1819, list_of_fixable_A[var]] = 0\n",
    "            if pd.isnull(DF.loc[i+1819, list_of_fixable_P[var]]):\n",
    "                DF.loc[i+1819, list_of_fixable_P[var]] = 0\n",
    "            if pd.isnull(DF.loc[i+1819, list_of_fixable_R[var]]):\n",
    "                DF.loc[i+1819, list_of_fixable_R[var]] = 0\n",
    "            if pd.isnull(DF.loc[i+1819, list_of_fixable_B[var]]):\n",
    "                DF.loc[i+1819, list_of_fixable_B[var]] = 0\n",
    "DF.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e75eb-ebe4-4286-a699-d4794349adb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## R E L E V A N T   C O D E\n",
    "\n",
    "RowsDF=[24,28,30,32]\n",
    "def drop_most_missing(df, rows):\n",
    "    complete_dfs = []\n",
    "    dropped_columns=[]\n",
    "    for i in range(len(df.columns)):\n",
    "        col_with_most_missing = df.isnull().sum().idxmax()\n",
    "        df = df.drop(col_with_most_missing, axis=1)\n",
    "        print(f\"Dropped column: {col_with_most_missing}\")\n",
    "        dropped_columns.append(col_with_most_missing)\n",
    "        print(f\"New shape: {df.shape}\")\n",
    "        complete_rows = df.dropna()\n",
    "        print(f\"Shape with complete rows only: {complete_rows.shape}\")\n",
    "        if i in rows:\n",
    "            complete_dfs.append(complete_rows)\n",
    "        print(i)\n",
    "    return complete_dfs, dropped_columns\n",
    "\n",
    "complete_dfs, dropped_columns = drop_most_missing(DF, RowsDF)\n",
    "newdf = complete_dfs[0]\n",
    "newdf2 = complete_dfs[1]\n",
    "newdf3 = complete_dfs[2]\n",
    "newdf4 = complete_dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c26a88-f968-4376-a2c7-7162eb1aaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88909825-43f9-4241-b25b-c715bf292a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
